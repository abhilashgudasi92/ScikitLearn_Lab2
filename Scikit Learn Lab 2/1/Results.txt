--> Decision Tree
	Best parameters:
		{'criterion': 'entropy',
 		 'max_depth': 14,
 		 'max_features': 7,
  		 'min_samples_leaf': 1,
 		 'min_samples_split': 2}
	
	Accuracy : 82.2%

	Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.90      0.96      0.93        27
          1       0.70      0.80      0.75        35
          2       0.94      0.83      0.88        36
          3       0.70      0.90      0.79        29
          4       0.76      0.83      0.79        30
          5       0.92      0.82      0.87        40
          6       0.93      0.86      0.89        44
          7       0.84      0.82      0.83        39
          8       0.81      0.64      0.71        39
          9       0.77      0.80      0.79        41

avg / total       0.83      0.82      0.82       360



--> Neural Net:
		Best parameters:
		{'activation': 'relu',
 		 'alpha': 0.1,
 		 'hidden_layer_sizes': (10, 10, 5),
 		 'learning_rate': 'constant',
 		 'learning_rate_init': 0.01}

		Accuracy  : 76.11%

		Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.93      0.96      0.95        27
          1       0.85      0.80      0.82        35
          2       0.97      0.94      0.96        36
          3       0.84      0.90      0.87        29
          4       1.00      0.97      0.98        30
          5       0.91      0.97      0.94        40
          6       0.98      0.93      0.95        44
          7       0.90      0.97      0.94        39
          8       0.45      0.26      0.33        39
          9       0.71      0.66      0.68        41

avg / total       0.85      0.83      0.83       360



--> Support Vector Machine:
		Best parameters:
		{'C': 100, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly', 'max_iter': 100}

		Accuracy :98.95%

	Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       1.00      1.00      1.00        27
          1       0.95      1.00      0.97        35
          2       1.00      1.00      1.00        36
          3       1.00      1.00      1.00        29
          4       1.00      1.00      1.00        30
          5       0.97      0.97      0.97        40
          6       1.00      0.98      0.99        44
          7       1.00      1.00      1.00        39
          8       1.00      0.97      0.99        39
          9       0.98      0.98      0.98        41

avg / total       0.99      0.99      0.99       360



--> Gaussian Naive Bayes(Since this has only one parameter we ran directly without grid search)
	
		Accuracy : 82.5%

		Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       1.00      1.00      1.00        27
          1       0.66      0.89      0.76        35
          2       0.94      0.47      0.63        36
          3       0.89      0.83      0.86        29
          4       1.00      0.73      0.85        30
          5       0.97      0.88      0.92        40
          6       1.00      1.00      1.00        44
          7       0.74      1.00      0.85        39
          8       0.54      0.82      0.65        39
          9       0.96      0.63      0.76        41

avg / total       0.87      0.82      0.83       360



--> Logistic Regression:
		
		Best parameters:
		{'C': 1.0,
 		 'fit_intercept': False,
  		 'max_iter': 1000,
 		 'penalty': 'l1',
 		 'tol': 0.01}
		
		Accuracy : 96.79%

		Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       1.00      1.00      1.00        27
          1       0.89      0.94      0.92        35
          2       0.97      0.94      0.96        36
          3       0.94      1.00      0.97        29
          4       1.00      1.00      1.00        30
          5       0.97      0.97      0.97        40
          6       0.98      0.98      0.98        44
          7       0.95      0.97      0.96        39
          8       0.92      0.92      0.92        39
          9       0.97      0.88      0.92        41

avg / total       0.96      0.96      0.96       360



--> k-Nearest Neighbors: 

		Best parameters:
		{'algorithm': 'auto', 'n_neighbors': 2, 'p': 2, 'weights': 'distance'}
	
		Accuracy : 98.88%

		Detailed classification report:

	The model is trained on the full development set.
	The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       1.00      1.00      1.00        27
          1       1.00      1.00      1.00        35
          2       1.00      0.97      0.99        36
          3       0.94      1.00      0.97        29
          4       1.00      1.00      1.00        30
          5       0.97      0.97      0.97        40
          6       1.00      1.00      1.00        44
          7       1.00      1.00      1.00        39
          8       1.00      1.00      1.00        39
          9       0.97      0.95      0.96        41

avg / total       0.99      0.99      0.99       360



	



